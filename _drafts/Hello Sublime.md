---
layout: post
title: "概率值校正"
description: "大多数的分类模型，得到的预测结果仅有定序意义，而不能够定量。很多情况下，仅仅得到一个好的AUC值是远远不够的，我们需要得到一个准确的概率值。这就要求，模型的输出结果从定序上升为定距。"
category: 机器学习
tags: 保序回归 普拉托校准
---

#机器学习的三个技巧
---
## 奥卡姆剃刀（Occam’s Razor）

*Entities should not be multiplied unnecessarily。*

如无必要，勿增实体。也就是简单有效原理。

具体到机器学习上，就是说，能够拟合数据的“simple model”(简单模型)才是我们需要的。
“Simple model”包含两个层面的意思，一是指simple hypothesis，每一个假设都只有少数的参数；二是指simple hypothesis set，假设空间只包含少数的假设。

$$simple H \\
 \Rightarrow smaller m_H(N)\\
 \Rightarrow less 'likely' to fit data perfectly \frac {m_H(N)}{2^N}\\
 \Rightarrow significant when it happens $$

如果假设空间$$H$$很大，那么成长函数$$m_H(N)$$也会很大；而即使是完全没有规律的数据，在成长函数$$m_H(N)$$足够大的情况下，也能够找到
一个完全拟合的模型。想象一下，一枚均匀的硬币，抛100次，如果我对抛硬币模型所做的假设空间对应的成长函数$$m_H(N)\geqslant 2^100$$，我也可以得到一个完全拟合结果的模型；但是这样的拟合完全没有意义。

反之如果假设空间$$H$$很小,$$m_H(N)$$也较小;在二分类问题中，这意味着一个模型完全拟合数据的概率很小，是$$\frac {m_H(N)}{2^N}$$。在这样的情况下，才能证明数据是有规律的，模型对数据的拟合才有意义。

###*Tips*
每次拿到数据后，可以先用线性模型进行拟合，如果线性模型对数据完全没有区分度，极有可能，数据本身就是随机无序的。

## 模拟真实的测试环境

1948年的美国总统竞选，一共有两个候选人，Truman和Dewey。一家报社为了预测选举结果，进行了电话投票，也就是打电话给选民，统计他们投票给了哪个候选人；结果显示，大部分接受采访的选民，都表示投票给了Dewey，于是，这家报社就发表了题为“Dewey Defeats Truman“的报道。结果真的是Dewey赢得了竞选吗？

！[Dewey wins the election?](1)

美国人民最终选择了Truman作为他们的第33届总统，Truman就是我们所熟知的杜鲁门总统。

为什么预测的结果和最终结果不符呢？是计票的错误，还是参与调研的选民说了谎呢？

真实的原因其实是，Dewey的竞选政策偏向于富人，Truman的竞选政策偏向于穷人。而在1948年，电话还是很贵的，这家报社采样的对象都是富人，所以，得到的结果也自然是偏向富人的Dewey获胜。

这告诉我们，训练集和最终的测试集一定要是iid同分布的。如果训练集的数据采样是有偏差的，那么学习得到的模型也一定是有偏差的。

关于训练集和测试集划分的另一个常见错误是忽略“时间”的影响，比如，我们之前做过的，消费预估模型。最初始的消费预估模型，训练集和测试集是对总体数据集$$D$$进行的一个随机划分，这通常会导致一个很不错的测试结果,但模型的实际运行效果却通常很次，为什么呢？

消费预估的目的是预测未来客户的消费数据，而当我们随机划分训练集和测试集时，训练集和测试集已经没有了时间上的区分。这时测试集对于训练集已经不是“未来”的数据：我们在训练的时候用到了一部分“未来”的数据，而测试时，用到了一部分“过去”的数据。事实上，大多数客户的消费曲线都是较为平滑的，如果我们知道了一个客户过去一个月和未来一个月的准确消费数据，需要预估当前月份的消费数据，那么直接使用这两个月（过去一个月和未来一个月）的平均值作为预估值，也会得到不错的结果。

对于包含时间属性的数据，训练集和测试集应当严格按照时间来划分，即某一时刻之前的数据为训练集，该时刻之后的用户记录为测试集。

###*Tips*

如果用户记录是带有时间戳的，那么，测试集通常采用“最近的记录”，训练集采用“过去的记录”，并在训练时对“近期的记录”附以较大的权重，通常可以产生不错的实际效果。

##平衡好“data-driven modeling（snooping，偷看）和“Validation（no snooping，不偷看）”

![snooping and no snooping](2)
上图是采用6年的外汇交易数据做训练集，最近2年的数据做测试集得到的一个外汇交易模型的测试结果。

红线和蓝线的唯一区别在于：红线采用snooping方法，计算整体样本（训练集+测试集）的均值和方差，对所有样本进行变量归一$$\frac{X-\mu}{\sigma}$$; 蓝线只对训练集计算均值和方差，然后进行变量归一。可以看到，snooping比no snooping方法有很大的“虚假”提升.

同样的问题在学术界也经常发生，比如一个标准数据集D，第一篇Paper提出了H1算法；第二篇Paper提出了H2算法，H2比H1在D上表现要好；第三篇Paper提出了H3算法，H3比H2在D上表现要好……

事实上上，因为后期模型实在前人研究基础上做出来的，作者通过阅读前人的论文而偷看了数据集。$$d_vc(H_m)=d_vc(\bi
gcup_{i=1}^{m}H_i)$$，后期模型的VC维很大，通常会导致一个不错的in-sample error，糟糕的generalization error。学术界有句话叫做:If you torture the data long enough, it will confess,说的就是这个道理.

实际上，人们要做模型，不可避免的要调研数据，进而对数据集做出某种假设，比如正态分布或是幂律分布。领域知识、对数据的调研都是对假设空间的一种污染，这其实都是snooping。一种比较极端的方法是，拿到数据集之后直接将测试集分隔，只对训练集进行分析。

###*Tips*

对数据集进行snooping是不可避免的，关键是一定要平衡好data-driven modelling（snooping）和validation（no-snooping）二者之间的关系。

  [1]: http://ww2.sinaimg.cn/mw690/7c225887tw1eft39y4qucj20gq0bsgms.jpg
  [2]: http://ww2.sinaimg.cn/mw690/7c225887tw1eft9p6udnij20eq0bhjs5.jpg